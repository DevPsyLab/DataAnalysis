---
title: "Structural Equation Modeling"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  error = TRUE,
  comment = "",
  class.source = "fold-show")
```

# Preamble

## Install Libraries

```{r, class.source = "fold-hide"}
#install.packages("remotes")
#remotes::install_github("DevPsyLab/petersenlab")
```

## Load Libraries

```{r, message = FALSE, warning = FALSE, class.source = "fold-hide"}
library("lavaan")
library("semTools")
library("semPlot")
library("lcsm")
library("MBESS")
library("tidyverse")
```

# Simulate Data

```{r, class.source = "fold-hide"}
set.seed(52242)

sampleSize <- 100

X <- rnorm(sampleSize)
M <- 0.5*X + rnorm(sampleSize)
Y <- 0.7*M + rnorm(sampleSize)

mydata <- data.frame(
  X = X,
  Y = Y,
  M = M)
```

# Import data

# Overview

https://isaactpetersen.github.io/Principles-Psychological-Assessment/sem.html

# Analysis examples

https://isaactpetersen.github.io/Principles-Psychological-Assessment/sem.html#semModelExample-sem

# Plot Observed Growth Curve

Transform data from wide to long format:

```{r}
Demo.growth$id <- 1:nrow(Demo.growth)

Demo.growth_long <- Demo.growth %>% 
  pivot_longer(
    cols = c(t1,t2,t3,t4),
    names_to = "variable",
    values_to = "value",
    names_pattern = "t(.)") %>% 
  rename(
    timepoint = variable,
    score = value
  )

Demo.growth_long$timepoint <- as.numeric(Demo.growth_long$timepoint)
```

Plot the observed trajectory for each participant:

```{r}
ggplot(
  data = Demo.growth_long,
  mapping = aes(
    x = timepoint,
    y = score,
    group = id)) +
  geom_line() +
  scale_x_continuous(
    breaks = 1:4,
    name = "Timepoint") +
  scale_y_continuous(
    name = "Score")
```

# Latent Growth Curve Model {#lgcm}

## Model Syntax

### Abbreviated

```{r}
lgcm1_syntax <- '
  # Intercept and slope
  intercept =~ 1*t1 + 1*t2 + 1*t3 + 1*t4
  slope =~ 0*t1 + 1*t2 + 2*t3 + 3*t4

  # Regression paths
  intercept ~ x1 + x2
  slope ~ x1 + x2
  
  # Time-varying covariates
  t1 ~ c1
  t2 ~ c2
  t3 ~ c3
  t4 ~ c4
'
```

### Full

```{r}
lgcm2_syntax <- '
  # Intercept and slope
  intercept =~ 1*t1 + 1*t2 + 1*t3 + 1*t4
  slope =~ 0*t1 + 1*t2 + 2*t3 + 3*t4

  # Regression paths
  intercept ~ x1 + x2
  slope ~ x1 + x2
  
  # Time-varying covariates
  t1 ~ c1
  t2 ~ c2
  t3 ~ c3
  t4 ~ c4
  
  # Constrain observed intercepts to zero
  t1 ~ 0
  t2 ~ 0
  t3 ~ 0
  t4 ~ 0
  
  # Estimate mean of intercept and slope
  intercept ~ 1
  slope ~ 1
'
```

## Fit the Model

### Abbreviated

```{r}
lgcm1_fit <- growth(
  lgcm1_syntax,
  data = Demo.growth,
  missing = "ML",
  estimator = "MLR",
  meanstructure = TRUE,
  int.ov.free = FALSE,
  int.lv.free = TRUE,
  fixed.x = FALSE,
  em.h1.iter.max = 100000)
```

### Full

```{r}
lgcm2_fit <- sem(
  lgcm2_syntax,
  data = Demo.growth,
  missing = "ML",
  estimator = "MLR",
  meanstructure = TRUE,
  fixed.x = FALSE,
  em.h1.iter.max = 100000)
```

## Summary Output

### Abbreviated

```{r}
summary(
  lgcm1_fit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

### Full

```{r}
summary(
  lgcm2_fit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

## Estimates of Model Fit

```{r}
fitMeasures(
  lgcm1_fit,
  fit.measures = c(
    "chisq", "df", "pvalue",
    "chisq.scaled", "df.scaled", "pvalue.scaled",
    "chisq.scaling.factor",
    "baseline.chisq","baseline.df","baseline.pvalue",
    "rmsea", "cfi", "tli", "srmr",
    "rmsea.robust", "cfi.robust", "tli.robust"))
```

## Residuals

```{r}
residuals(
  lgcm1_fit,
  type = "cor")
```

## Modification Indices

```{r}
modificationindices(
  lgcm1_fit,
  sort. = TRUE)
```

## Internal Consistency Reliability

```{r}
compRelSEM(lgcm1_fit)
```

## Path Diagram

```{r}
semPaths(
  lgcm1_fit,
  what = "Std.all",
  layout = "tree2",
  edge.label.cex = 1.5)
```

## Plot Trajectories

### Protoypical Growth Curve

Calculated from intercept and slope parameters:

```{r}
lgcm1_intercept <- coef(lgcm1_fit)["intercept~1"]
lgcm1_slope <- coef(lgcm1_fit)["slope~1"]

ggplot() +
  xlab("Timepoint") +
  ylab("Score") +
  scale_x_continuous(
    limits = c(0, 3),
    labels = 1:4) +
  scale_y_continuous(
    limits = c(0, 5)) +
  geom_abline(
    mapping = aes(
      slope = lgcm1_slope,
      intercept = lgcm1_intercept))
```

Calculated manually:

```{r}
timepoints <- 4

newData <- expand.grid(
  time = c(1, 4)
)

newData$predictedValue <- NA
newData$predictedValue[which(newData$time == 1)] <- lgcm1_intercept
newData$predictedValue[which(newData$time == 4)] <- lgcm1_intercept + (timepoints - 1)*lgcm1_slope

ggplot(
  data = newData,
  mapping = aes(x = time, y = predictedValue)) +
  xlab("Timepoint") +
  ylab("Score") +
  scale_y_continuous(
    limits = c(0, 5)) +
  geom_line()
```

### Individuals' Growth Curves

Calculated from intercept and slope parameters:

```{r}
newData <- as.data.frame(predict(lgcm1_fit))
newData$id <- row.names(newData)

ggplot(
  data = newData) +
  xlab("Timepoint") +
  ylab("Score") +
  scale_x_continuous(
    limits = c(0, 3),
    labels = 1:4) +
  scale_y_continuous(
    limits = c(-10, 20)) +
  geom_abline(
    mapping = aes(
      slope = slope,
      intercept = intercept))
```

Calculated manually:

```{r}
newData$t1 <- newData$intercept
newData$t4 <- newData$intercept + (timepoints - 1)*newData$slope

newData2 <- pivot_longer(
  newData,
  cols = c(t1, t4)) %>% 
  select(-intercept, -slope)

newData2$time <- NA
newData2$time[which(newData2$name == "t1")] <- 1
newData2$time[which(newData2$name == "t4")] <- 4

ggplot(
  data = newData2,
  mapping = aes(x = time, y = value, group = factor(id))) +
  xlab("Timepoint") +
  ylab("Score") +
  scale_y_continuous(
    limits = c(-10, 20)) +
  geom_line()
```

### Individuals' Trajectories Overlaid with Prototypical Trajectory

```{r}
newData <- as.data.frame(predict(lgcm1_fit))
newData$id <- row.names(newData)

ggplot(
  data = newData) +
  xlab("Timepoint") +
  ylab("Score") +
  scale_x_continuous(
    limits = c(0, 3),
    labels = 1:4) +
  scale_y_continuous(
    limits = c(-10, 20)) +
  geom_abline(
    mapping = aes(
      slope = slope,
      intercept = intercept)) +
  geom_abline(
    mapping = aes(
      slope = lgcm1_slope,
      intercept = lgcm1_intercept),
    color = "blue",
    linewidth = 2)
```

# Latent Change Score Model {#lcsm}

## Model Syntax

```{r}
bivariateLCSM_syntax <- specify_bi_lcsm(
  timepoints = 10,
  var_x = "x",
  model_x = list(
    alpha_constant = TRUE, # alpha = intercept (constant change factor)
    beta = TRUE, # beta = proportional change factor (latent true score predicting its change score)
    phi = TRUE), # phi = autoregression of change scores
  var_y = "y",
  model_y = list(
    alpha_constant = TRUE, # alpha = intercept (constant change factor)
    beta = TRUE, # beta = proportional change factor (latent true score predicting its change score)
    phi = TRUE), # phi = autoregression of change scores
  coupling = list(
    delta_lag_xy = TRUE,
    delta_lag_yx = TRUE),
  change_letter_x = "g",
  change_letter_y = "j")

cat(bivariateLCSM_syntax)
```

## Fit the Model

```{r}
bivariateLCSM_fit <- fit_bi_lcsm(
  data = data_bi_lcsm,
  var_x = names(data_bi_lcsm)[2:4],
  var_y = names(data_bi_lcsm)[12:14],
  model_x = list(
    alpha_constant = TRUE, # alpha = intercept (constant change factor)
    beta = TRUE, # beta = proportional change factor (latent true score predicting its change score)
    phi = FALSE), # phi = autoregression of change scores
  model_y = list(
    alpha_constant = TRUE, # alpha = intercept (constant change factor)
    beta = TRUE, # beta = proportional change factor (latent true score predicting its change score)
    phi = TRUE), # phi = autoregression of change scores
  coupling = list(
    delta_lag_xy = TRUE,
    xi_lag_yx = TRUE)
  )
```

## Summary Output

```{r}
summary(
  bivariateLCSM_fit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

## Estimates of Model Fit

```{r}
fitMeasures(
  bivariateLCSM_fit,
  fit.measures = c(
    "chisq", "df", "pvalue",
    "chisq.scaled", "df.scaled", "pvalue.scaled",
    "chisq.scaling.factor",
    "baseline.chisq","baseline.df","baseline.pvalue",
    "rmsea", "cfi", "tli", "srmr",
    "rmsea.robust", "cfi.robust", "tli.robust"))
```

## Residuals

```{r}
residuals(
  bivariateLCSM_fit,
  type = "cor")
```

## Modification Indices

```{r}
modificationindices(
  bivariateLCSM_fit,
  sort. = TRUE)
```

## Path Diagram

```{r}
semPaths(
  bivariateLCSM_fit,
  what = "Std.all",
  layout = "tree2",
  edge.label.cex = 1.5)

plot_lcsm(
  lavaan_object = bivariateLCSM_fit,
  lcsm = "bivariate",
  lavaan_syntax = bivariateLCSM_syntax)
```

## Plot Trajectories

```{r}
plot_trajectories(
  data_bi_lcsm,
  id_var = "id",
  var_list = c("y1", "y2", "y3", "y4", "y5",
               "y6", "y7", "y8", "y9", "y10"),
  xlab = "Time",
  ylab = "Y Score",
  connect_missing = FALSE)
```

# Cross-Lagged Panel Model {#clpm}

## Model Syntax

```{r}
clpm_syntax <- '
  # Autoregressive Paths
  t4 ~ t3
  t3 ~ t2
  t2 ~ t1
  
  c4 ~ c3
  c3 ~ c2
  c2 ~ c1
  
  # Concurrent Covariances
  t1 ~~ c1
  t2 ~~ c2
  t3 ~~ c3
  t4 ~~ c4
  
  # Cross-Lagged Paths
  t4 ~ c3
  t3 ~ c2
  t2 ~ c1
  
  c4 ~ t3
  c3 ~ t2
  c2 ~ t1
'
```

## Fit the Model

```{r}
clpm_fit <- sem(
  clpm_syntax,
  data = Demo.growth,
  missing = "ML",
  estimator = "MLR",
  meanstructure = TRUE,
  std.lv = TRUE,
  fixed.x = FALSE,
  em.h1.iter.max = 100000)
```

## Summary Output

```{r}
summary(
  clpm_fit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

## Estimates of Model Fit

```{r}
fitMeasures(
  clpm_fit,
  fit.measures = c(
    "chisq", "df", "pvalue",
    "chisq.scaled", "df.scaled", "pvalue.scaled",
    "chisq.scaling.factor",
    "baseline.chisq","baseline.df","baseline.pvalue",
    "rmsea", "cfi", "tli", "srmr",
    "rmsea.robust", "cfi.robust", "tli.robust"))
```

## Residuals

```{r}
residuals(
  clpm_fit,
  type = "cor")
```

## Modification Indices

```{r}
modificationindices(
  clpm_fit,
  sort. = TRUE)
```

## Path Diagram

```{r}
semPaths(
  clpm_fit,
  what = "Std.all",
  layout = "tree2",
  edge.label.cex = 1.5)
```

# Random Intercept Cross-Lagged Panel Model {#riclpm}

## Model Syntax

### Abbreviated

Adapted from Mulder & Hamaker (2021): https://doi.org/10.1080/10705511.2020.1784738

https://jeroendmulder.github.io/RI-CLPM/lavaan.html (archived at https://perma.cc/2K6A-WUJQ)

```{r}
riclpm1_syntax <- '
  # Random Intercepts
  t =~ 1*t1 + 1*t2 + 1*t3 + 1*t4
  c =~ 1*c1 + 1*c2 + 1*c3 + 1*c4
  
  # Create Within-Person Centered Variables
  wt1 =~ 1*t1
  wt2 =~ 1*t2
  wt3 =~ 1*t3
  wt4 =~ 1*t4
  
  wc1 =~ 1*c1
  wc2 =~ 1*c2
  wc3 =~ 1*c3
  wc4 =~ 1*c4
  
  # Autoregressive Paths
  wt4 ~ wt3
  wt3 ~ wt2
  wt2 ~ wt1
  
  wc4 ~ wc3
  wc3 ~ wc2
  wc2 ~ wc1
  
  # Concurrent Covariances
  wt1 ~~ wc1
  wt2 ~~ wc2
  wt3 ~~ wc3
  wt4 ~~ wc4
  
  # Cross-Lagged Paths
  wt4 ~ wc3
  wt3 ~ wc2
  wt2 ~ wc1
  
  wc4 ~ wt3
  wc3 ~ wt2
  wc2 ~ wt1
  
  # Variance and Covariance of Random Intercepts
  t ~~ t
  c ~~ c
  t ~~ c
  
  # Variances of Within-Person Centered Variables
  wt1 ~~ wt1
  wt2 ~~ wt2
  wt3 ~~ wt3
  wt4 ~~ wt4
  
  wc1 ~~ wc1
  wc2 ~~ wc2
  wc3 ~~ wc3
  wc4 ~~ wc4
'
```

### Full

Adapted from Mund & Nestler (2017): https://osf.io/a4dhk

```{r}
riclpm2_syntax <- '
  # Random Intercepts
  t =~ 1*t1 + 1*t2 + 1*t3 + 1*t4
  c =~ 1*c1 + 1*c2 + 1*c3 + 1*c4
  
  # Create Within-Person Centered Variables
  wt1 =~ 1*t1
  wt2 =~ 1*t2
  wt3 =~ 1*t3
  wt4 =~ 1*t4
  
  wc1 =~ 1*c1
  wc2 =~ 1*c2
  wc3 =~ 1*c3
  wc4 =~ 1*c4
  
  # Autoregressive Paths
  wt4 ~ wt3
  wt3 ~ wt2
  wt2 ~ wt1
  
  wc4 ~ wc3
  wc3 ~ wc2
  wc2 ~ wc1
  
  # Concurrent Covariances
  wt1 ~~ wc1
  wt2 ~~ wc2
  wt3 ~~ wc3
  wt4 ~~ wc4
  
  # Cross-Lagged Paths
  wt4 ~ wc3
  wt3 ~ wc2
  wt2 ~ wc1
  
  wc4 ~ wt3
  wc3 ~ wt2
  wc2 ~ wt1
  
  # Variance and Covariance of Random Intercepts
  t ~~ t
  c ~~ c
  t ~~ c
  
  # Variances of Within-Person Centered Variables
  wt1 ~~ wt1
  wt2 ~~ wt2
  wt3 ~~ wt3
  wt4 ~~ wt4
  
  wc1 ~~ wc1
  wc2 ~~ wc2
  wc3 ~~ wc3
  wc4 ~~ wc4
  
  # Fix Error Variances of Observed Variables to Zero
  t1 ~~ 0*t1
  t2 ~~ 0*t2
  t3 ~~ 0*t3
  t4 ~~ 0*t4
  
  c1 ~~ 0*c1
  c2 ~~ 0*c2
  c3 ~~ 0*c3
  c4 ~~ 0*c4
  
  # Fix the Covariances Between the Random Intercepts and the Latents at T1 to Zero
  wt1 ~~ 0*t
  wt1 ~~ 0*c
  
  wc1 ~~ 0*t
  wc1 ~~ 0*c
  
  # Estimate Observed Intercepts
  t1 ~ 1
  t2 ~ 1
  t3 ~ 1
  t4 ~ 1
  
  c1 ~ 1
  c2 ~ 1
  c3 ~ 1
  c4 ~ 1
  
  # Fix the Means of the Latents to Zero
  wt1 ~ 0*1
  wt2 ~ 0*1
  wt3 ~ 0*1
  wt4 ~ 0*1
  
  wc1 ~ 0*1
  wc2 ~ 0*1
  wc3 ~ 0*1
  wc4 ~ 0*1
  
  t ~ 0*1
  c ~ 0*1
'
```

## Fit the Model

### Abbreviated

```{r}
riclpm1_fit <- lavaan(
  riclpm1_syntax,
  data = Demo.growth,
  missing = "ML",
  estimator = "MLR",
  meanstructure = TRUE,
  int.ov.free = TRUE,
  em.h1.iter.max = 100000)
```

### Full

```{r}
riclpm2_fit <- sem(
  riclpm2_syntax,
  data = Demo.growth,
  missing = "ML",
  estimator = "MLR",
  em.h1.iter.max = 100000)
```

## Summary Output

### Abbreviated

```{r}
summary(
  riclpm1_fit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

### Full

```{r}
summary(
  riclpm2_fit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

## Estimates of Model Fit

```{r}
fitMeasures(
  riclpm1_fit,
  fit.measures = c(
    "chisq", "df", "pvalue",
    "chisq.scaled", "df.scaled", "pvalue.scaled",
    "chisq.scaling.factor",
    "baseline.chisq","baseline.df","baseline.pvalue",
    "rmsea", "cfi", "tli", "srmr",
    "rmsea.robust", "cfi.robust", "tli.robust"))
```

## Residuals

```{r}
residuals(
  riclpm1_fit,
  type = "cor")
```

## Modification Indices

```{r}
modificationindices(
  riclpm1_fit,
  sort. = TRUE)
```

## Internal Consistency Reliability

```{r}
compRelSEM(riclpm1_fit)
```

## Path Diagram

```{r}
semPaths(
  riclpm1_fit,
  what = "Std.all",
  layout = "tree2",
  edge.label.cex = 1.5)
```

# Mediation {#mediation}

## Model Syntax

```{r}
mediationModel <- '
# direct effect (cPrime)
Y ~ direct*X

# mediator
M ~ a*X
Y ~ b*M

# indirect effect = a*b
indirect := a*b

# total effect (c)
total := direct + indirect
'
```

## Fit the Model

To get a robust estimate of the indirect effect, we obtain bootstrapped estimates from 1,000 bootstrap draws.
Typically, we would obtain bootstrapped estimates from 10,000 bootstrap draws, but this example uses only 1,000 bootstrap draws for a shorter runtime.

```{r}
mediationFit <- sem(
  mediationModel,
  data = mydata,
  se = "bootstrap",
  bootstrap = 1000, # generally use 10,000 bootstrap draws; this example uses 1,000 for speed
  missing = "ML",
  estimator = "ML",
  std.lv = TRUE)
```

## Summary Output

```{r}
summary(
  mediationFit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

## Parameter Estimates

```{r}
mediationFit_estimates <- parameterEstimates(
  mediationFit,
  boot.ci.type = "bca.simple",
  standardized = TRUE)

mediationFit_estimates
```

## Indirect Effect

### Parameter Estimate

```{r}
mediationFit_estimates %>% 
  filter(label == "indirect")
```

### Effect Size

#### Standardized Estimate ($\beta$)

$$
\beta(ab) = ab \cdot \frac{SD_\text{Y}}{SD_\text{X}}
$$

```{r}
mediationFit_indirect <- mediationFit_estimates %>% 
  filter(label == "indirect") %>% 
  select(std.all) %>% 
  as.numeric

mediationFit_indirect
```

#### Proportion Mediated (*P*<sub>*M*</sub>) {#proportionMediated}

$$
P_M = \frac{ab}{c} = \frac{ab}{c' + ab}
$$

Effect size: Proportion mediated (*P*<sub>*M*</sub>); i.e., the proportion of the total effect that is mediated; calculated by the magnitude of the indirect effect divided by the magnitude of the total effect:

```{r}
mediationFit_total <- mediationFit_estimates %>% 
  filter(label == "total") %>% 
  select(std.all) %>% 
  as.numeric

mediationFit_pm <- mediationFit_indirect / mediationFit_total
mediationFit_pm
```

In this case, the direct effect and indirect effect have opposite signs (negative and positive, respectively).
This is called *inconsistent mediation*, and renders the estimate of proportion mediated not a meaningful estimate of effect size (which explains why it the estimate exceeds 1.0; Fairchild & McDaniel, 2017).

#### Proportion of Variance in Y That is Explained by the Indirect Effect (*R*<sup>2</sup><sub>mediated</sub>) {#rSquaredMediated}

Formulas from Lachowicz et al. (2018):

$$
\begin{aligned}
  R^2_\text{mediated} &= r^2_{\text{MY}} - (R^2_{\text{Y} \cdot \text{MX}} - r^2_{\text{XY}}) \\
  &= (\beta^2_{\text{YM} \cdot \text{X}} + \beta_{\text{YX} \cdot \text{M}} \cdot \beta_{\text{MX}}) ^2 - [\beta^2_{\text{YX}} + \beta^2_{\text{YM} \cdot \text{X}}(1 - \beta^2_{\text{MX}}) - \beta^2_{\text{YX}}]
\end{aligned}
$$

```{r}
rXY <- as.numeric(cor.test(
  ~ X + Y,
  data = mydata
)$estimate)

rMY <- as.numeric(cor.test(
  ~ M + Y,
  data = mydata
)$estimate)

RsquaredYmx <- summary(lm(
  Y ~ M + X,
  data = mydata))$r.squared

RsquaredMed1 <- (rMY^2) - (RsquaredYmx - (rXY^2))
RsquaredMed1

betaYMgivenX <- mediationFit_estimates %>% 
  filter(label == "b") %>% 
  select(std.all) %>% 
  as.numeric

betaYXgivenM <- mediationFit_estimates %>% 
  filter(label == "direct") %>% 
  select(std.all) %>% 
  as.numeric

betaMX <- mediationFit_estimates %>% 
  filter(label == "a") %>% 
  select(std.all) %>% 
  as.numeric

betaYX <- as.numeric(cor.test(
  ~ X + Y,
  data = mydata
)$estimate)

RsquaredMed2 <- ((betaYMgivenX + (betaYXgivenM * betaMX))^2) - ((betaYX^2) + (betaYMgivenX^2)*(1 - (betaMX^2)) - (betaYX^2))
RsquaredMed2
```

#### The Proportion of Variance in Y That is Accounted for Jointly by M and X (upsilon; $v$) {#upsilon}

Formulas from Lachowicz et al. (2018):

$$
\begin{aligned}
  v &= (r_{\text{YM}} - \beta_{\text{MX}} \cdot \beta^2_{\text{YX} \cdot \text{M}}) ^ 2 - (R^2_{\text{Y} \cdot \text{MX}} - r^2_{\text{YX}})\\
  &= \beta^2_a \cdot \beta^2_b
\end{aligned}
$$

where $a$ is the $a$ path ($\beta^2_{\text{MX}}$), and $b$ is the $b$ path ($\beta^2_{\text{YM} \cdot \text{X}}$).

The estimate corrects for spurious correlation induced by the ordering of variables.

```{r}
upsilon1 <- ((rMY - (betaMX * (betaYXgivenM^2)))^2) - (RsquaredYmx - (rXY^2))
upsilon1

upsilon2 <- (betaYMgivenX^2) - (RsquaredYmx - (rXY^2))
upsilon2

upsilon3 <- mediationFit_indirect ^ 2
upsilon3

upsilon(
  x = mydata$X,
  mediator = mydata$M,
  dv = mydata$Y,
  bootstrap = FALSE
)
```

#### Ratio of the Indirect Effect Relative to Its Maximum Possible Value in the Data ($\kappa^2$) {#kappaSquared}

$$
\kappa^2 = \frac{ab}{\text{MAX}(ab)}
$$

Kappa-squared ($\kappa^2$) is the ratio of the indirect effect relative to its maximum possible value in the data given the observed variability of X, Y, and M and their intercorrelations in the data.
This estimate is no longer recommended (Wen & Fan, 2015).

#### Other Effect Sizes

```{r}
mediation(
  x = mydata$X,
  mediator = mydata$M,
  dv = mydata$Y,
  bootstrap = FALSE
)
```

## Estimates of Model Fit

The model is saturated because it has as many estimated parameters as there are data points (i.e., in terms of means, variances, and covariances), so it has zero degrees of freedom.
Because the model is saturated, it has "perfect" fit.

```{r}
fitMeasures(
  mediationFit,
  fit.measures = c(
    "chisq", "df", "pvalue",
    "baseline.chisq","baseline.df","baseline.pvalue",
    "rmsea", "cfi", "tli", "srmr"))
```

## Residuals

```{r}
residuals(mediationFit, type = "cor")
```

## Modification Indices

```{r}
modificationindices(mediationFit, sort. = TRUE)
```

## Internal Consistency Reliability

```{r}
compRelSEM(mediationFit)
```

## Path Diagram

```{r}
semPaths(
  mediationFit,
  what = "Std.all",
  layout = "tree2",
  edge.label.cex = 1.5)
```

# Power analysis

https://isaactpetersen.github.io/Principles-Psychological-Assessment/sem.html#monteCarloPowerAnalysis

# Session Info

```{r, class.source = "fold-hide"}
sessionInfo()
```
